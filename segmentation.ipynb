{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/+7vWW4mkCPLAhYxMdIPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coffinbrain/lessons/blob/main/segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o-yE48GwMEM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from torch.utils.data import Dataset\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from math import log10, exp\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "import math\n",
        "\n",
        "plt.rcParams['font.sans-serif'] = [\"SimHei\"]\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
        "\n",
        "\n",
        "def load_img(filepath):\n",
        "    img = Image.open(filepath).convert('YCbCr')\n",
        "    y, _, _ = img.split()\n",
        "    return y\n",
        "\n",
        "\n",
        "CROP_SIZE = 300\n",
        "\n",
        "\n",
        "class DatasetFromFolder(Dataset):\n",
        "    def __init__(self, image_dir, zoom_factor):\n",
        "        super(DatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(image_dir, x)\n",
        "                                for x in listdir(image_dir) if is_image_file(x)]\n",
        "        crop_size = CROP_SIZE - (CROP_SIZE % zoom_factor)\n",
        "        # 从图片中心裁剪成300*300\n",
        "        self.input_transform = transforms.Compose([transforms.CenterCrop(crop_size),\n",
        "                                                   transforms.Resize(\n",
        "                                                       crop_size // zoom_factor),\n",
        "                                                   transforms.Resize(\n",
        "                                                       crop_size, interpolation=Image.BICUBIC),\n",
        "                                                   # BICUBIC 双三次插值\n",
        "                                                   transforms.ToTensor()])\n",
        "        self.target_transform = transforms.Compose(\n",
        "            [transforms.CenterCrop(crop_size), transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input = load_img(self.image_filenames[index])\n",
        "        target = input.copy()\n",
        "        input = self.input_transform(input)\n",
        "        target = self.target_transform(target)\n",
        "        return input, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)"
      ],
      "metadata": {
        "id": "OMKvyCHKwRYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def psnr(loss):\n",
        "    return 10 * log10(1 / loss.item())"
      ],
      "metadata": {
        "id": "ehWVPqadwRWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算一维的高斯分布向量\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor(\n",
        "        [exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "\n",
        "# 创建高斯核，通过两个一维高斯分布向量进行矩阵乘法得到\n",
        "# 可以设定channel参数拓展为3通道\n",
        "def create_window(window_size, channel=1):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(\n",
        "        _1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = _2D_window.expand(\n",
        "        channel, 1, window_size, window_size).contiguous()\n",
        "    return window\n",
        "\n",
        "\n",
        "# 计算SSIM\n",
        "# 直接使用SSIM的公式，但是在计算均值时，不是直接求像素平均值，而是采用归一化的高斯核卷积来代替。\n",
        "# 在计算方差和协方差时用到了公式Var(X)=E[X^2]-E[X]^2, cov(X,Y)=E[XY]-E[X]E[Y].\n",
        "def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=None):\n",
        "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
        "    if val_range is None:\n",
        "        if torch.max(img1) > 128:\n",
        "            max_val = 255\n",
        "        else:\n",
        "            max_val = 1\n",
        "\n",
        "        if torch.min(img1) < -0.5:\n",
        "            min_val = -1\n",
        "        else:\n",
        "            min_val = 0\n",
        "        L = max_val - min_val\n",
        "    else:\n",
        "        L = val_range\n",
        "\n",
        "    padd = 0\n",
        "    (_, channel, height, width) = img1.size()\n",
        "    if window is None:\n",
        "        real_size = min(window_size, height, width)\n",
        "        window = create_window(real_size, channel=channel).to(img1.device)\n",
        "\n",
        "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd,\n",
        "                         groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd,\n",
        "                         groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=padd,\n",
        "                       groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = (0.01 * L) ** 2\n",
        "    C2 = (0.03 * L) ** 2\n",
        "\n",
        "    v1 = 2.0 * sigma12 + C2\n",
        "    v2 = sigma1_sq + sigma2_sq + C2\n",
        "    cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
        "\n",
        "    if size_average:\n",
        "        ret = ssim_map.mean()\n",
        "    else:\n",
        "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "    if full:\n",
        "        return ret, cs\n",
        "    return ret\n",
        "\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size=11, size_average=True, val_range=None):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.val_range = val_range\n",
        "\n",
        "        # Assume 1 channel for SSIM\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.dtype == img1.dtype:\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel).to(\n",
        "                img1.device).type(img1.dtype)\n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "        return ssim(img1, img2, window=window, window_size=self.window_size, size_average=self.size_average)"
      ],
      "metadata": {
        "id": "21vC8EsgwRTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SRCNN(nn.Module):\n",
        "    def __init__(self, upscale_factor):\n",
        "        super(SRCNN, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2,\n",
        "                               kernel_size=3, stride=1, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv4.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "SqnAcXdpwRQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zoom_factor = 2\n",
        "nb_epochs = 500\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "BATCH_SIZE = 4\n",
        "NUM_WORKERS = 0\n",
        "trainset = DatasetFromFolder(r\"./data/images/train\", zoom_factor)\n",
        "valset = DatasetFromFolder(r\"./data/images/train\", zoom_factor)\n",
        "trainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "valloader = DataLoader(dataset=valset, batch_size=BATCH_SIZE,\n",
        "                       shuffle=False, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "V_yY750OwRNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SRCNN(1).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(\n",
        "    [\n",
        "        {\"params\": model.conv1.parameters(), \"lr\": 0.0001},\n",
        "        {\"params\": model.conv2.parameters(), \"lr\": 0.0001},\n",
        "        {\"params\": model.conv3.parameters(), \"lr\": 0.00001},\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "best_psnr = 0.0\n",
        "for epoch in range(nb_epochs):\n",
        "    # Train\n",
        "    epoch_loss = 0\n",
        "    for iteration, batch in enumerate(trainloader):\n",
        "        input, target = batch[0].to(device), batch[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(input)\n",
        "        loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print(f\"Epoch {epoch}. Training loss: {epoch_loss / len(trainloader)}\")\n",
        "    # Val\n",
        "    sum_psnr = 0.0\n",
        "    sum_ssim = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in valloader:\n",
        "            input, target = batch[0].to(device), batch[1].to(device)\n",
        "            out = model(input)\n",
        "            loss = criterion(out, target)\n",
        "            pr = psnr(loss)\n",
        "            sm = ssim(input, out)\n",
        "            sum_psnr += pr\n",
        "            sum_ssim += sm\n",
        "    print(f\"Average PSNR: {sum_psnr / len(valloader)} dB.\")\n",
        "    print(f\"Average SSIM: {sum_ssim / len(valloader)} \")\n",
        "    avg_psnr = sum_psnr / len(valloader)\n",
        "    if avg_psnr >= best_psnr:\n",
        "        best_psnr = avg_psnr\n",
        "        torch.save(model, r\"best_model_SRCNN.pth\")"
      ],
      "metadata": {
        "id": "70_PaP_xwRK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4\n",
        "model_path = \"best_model_SRCNN.pth\"\n",
        "testset = DatasetFromFolder(r\"./data/images/test\", zoom_factor)\n",
        "testloader = DataLoader(dataset=testset, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False, num_workers=NUM_WORKERS)\n",
        "sum_psnr = 0.0\n",
        "sum_ssim = 0.0\n",
        "model = torch.load(model_path).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "with torch.no_grad():\n",
        "    for batch in testloader:\n",
        "        input, target = batch[0].to(device), batch[1].to(device)\n",
        "        out = model(input)\n",
        "        loss = criterion(out, target)\n",
        "        pr = psnr(loss)\n",
        "        sm = ssim(input, out)\n",
        "        sum_psnr += pr\n",
        "        sum_ssim += sm\n",
        "print(f\"Test Average PSNR: {sum_psnr / len(testloader)} dB\")\n",
        "print(f\"Test Average SSIM: {sum_ssim / len(testloader)} \")"
      ],
      "metadata": {
        "id": "E_5TqUbewRIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FuPAOwdLwRFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}